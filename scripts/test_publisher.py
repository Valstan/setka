#!/usr/bin/env python3
"""
–¢–µ—Å—Ç VK Publisher

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –≤ VK –≥—Ä—É–ø–ø—É.

Usage:
    python scripts/test_publisher.py
"""
import sys
import os
import asyncio
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.publisher.vk_publisher import VKPublisher
from config.runtime import VK_TOKENS
from database.connection import AsyncSessionLocal
from database.models import Post, Region
from sqlalchemy import select, and_
from datetime import datetime, timedelta

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_simple_publish():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
    logger.info("=" * 80)
    logger.info("TEST 1: Simple text publish")
    logger.info("=" * 80)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω VALSTAN
    vk_token = VK_TOKENS.get("VALSTAN")
    if not vk_token:
        logger.error("‚ùå VK token VALSTAN not found in config")
        return False
    
    try:
        publisher = VKPublisher(vk_token)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥—Ä—É–ø–ø–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        logger.info("Getting user's groups...")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç
        test_text = """üî• –¢–µ—Å—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ SETKA v1.0

üì∞ –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π
üïê –í—Ä–µ–º—è: {time}

‚úÖ VK Publisher —Ä–∞–±–æ—Ç–∞–µ—Ç!

#—Ç–µ—Å—Ç #SETKA""".format(time=datetime.now().strftime("%H:%M:%S"))
        
        logger.info(f"Test text prepared ({len(test_text)} chars)")
        logger.info(f"\n{test_text}\n")
        
        # –í–ê–ñ–ù–û: –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å ID –≤–∞—à–µ–π –≥—Ä—É–ø–ø—ã
        # –ù–∞–ø—Ä–∏–º–µ—Ä: -123456789
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º, —á—Ç–æ publisher –≥–æ—Ç–æ–≤
        logger.info("‚ö†Ô∏è  To publish, you need to specify your VK group ID")
        logger.info("‚ö†Ô∏è  Example: target_group_id = -123456789")
        logger.info("‚ö†Ô∏è  Skipping actual publish in test mode")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}", exc_info=True)
        return False


async def test_digest_creation():
    """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤"""
    logger.info("=" * 80)
    logger.info("TEST 2: Digest creation from real posts")
    logger.info("=" * 80)
    
    try:
        async with AsyncSessionLocal() as session:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–≥–∏–æ–Ω –ú–∞–ª–º—ã–∂
            result = await session.execute(
                select(Region).where(Region.code == 'mi')
            )
            region = result.scalar_one_or_none()
            
            if not region:
                logger.error("‚ùå Region 'mi' not found")
                return False
            
            logger.info(f"‚úÖ Region found: {region.name}")
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-5 –ø–æ—Å—Ç–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            cutoff_time = datetime.now() - timedelta(hours=24)
            posts_result = await session.execute(
                select(Post).where(
                    and_(
                        Post.region_id == region.id,
                        Post.date_published >= cutoff_time,
                        Post.ai_analyzed == True
                    )
                ).order_by(Post.ai_score.desc()).limit(5)
            )
            posts = list(posts_result.scalars())
            
            logger.info(f"‚úÖ Found {len(posts)} posts")
            
            if not posts:
                logger.warning("‚ö†Ô∏è  No posts found in last 24 hours")
                # –ü—Ä–æ–±—É–µ–º –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                posts_result = await session.execute(
                    select(Post).where(
                        and_(
                            Post.region_id == region.id,
                            Post.ai_analyzed == True
                        )
                    ).order_by(Post.ai_score.desc()).limit(5)
                )
                posts = list(posts_result.scalars())
                logger.info(f"‚úÖ Found {len(posts)} posts (all time)")
            
            if not posts:
                logger.error("‚ùå No analyzed posts found for region")
                return False
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç
            from modules.aggregation.aggregator import NewsAggregator
            
            aggregator = NewsAggregator(max_posts_per_digest=5)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
            title = f"üì∞ –ù–û–í–û–°–¢–ò {region.name.upper()}"
            hashtags = [f"#–ù–æ–≤–æ—Å—Ç–∏{region.code.upper()}"]
            
            digest = await aggregator.aggregate(
                posts=posts,
                title=title,
                hashtags=hashtags
            )
            
            if not digest:
                logger.error("‚ùå Failed to create digest")
                return False
            
            logger.info("‚úÖ Digest created successfully!")
            logger.info(f"   Posts: {digest.sources_count}")
            logger.info(f"   Total views: {digest.total_views}")
            logger.info(f"   Total likes: {digest.total_likes}")
            logger.info(f"   Text length: {len(digest.aggregated_text)} chars")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –¥–∞–π–¥–∂–µ—Å—Ç–∞
            logger.info("\n" + "=" * 80)
            logger.info("DIGEST PREVIEW:")
            logger.info("=" * 80)
            preview = digest.aggregated_text[:500]
            logger.info(preview + "..." if len(digest.aggregated_text) > 500 else preview)
            logger.info("=" * 80 + "\n")
            
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}", exc_info=True)
        return False


async def test_full_workflow():
    """–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç workflow: —Å–æ–∑–¥–∞–Ω–∏–µ + –ø—É–±–ª–∏–∫–∞—Ü–∏—è (–¥–µ–º–æ)"""
    logger.info("=" * 80)
    logger.info("TEST 3: Full workflow (demo)")
    logger.info("=" * 80)
    
    try:
        vk_token = VK_TOKENS.get("VALSTAN")
        if not vk_token:
            logger.error("‚ùå VK token not found")
            return False
        
        publisher = VKPublisher(vk_token)
        
        async with AsyncSessionLocal() as session:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–≥–∏–æ–Ω
            result = await session.execute(
                select(Region).where(Region.code == 'mi')
            )
            region = result.scalar_one_or_none()
            
            if not region:
                logger.error("‚ùå Region not found")
                return False
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã
            posts_result = await session.execute(
                select(Post).where(
                    and_(
                        Post.region_id == region.id,
                        Post.ai_analyzed == True
                    )
                ).order_by(Post.ai_score.desc()).limit(5)
            )
            posts = list(posts_result.scalars())
            
            if not posts:
                logger.error("‚ùå No posts found")
                return False
            
            logger.info(f"‚úÖ Found {len(posts)} posts for region {region.name}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç
            from modules.aggregation.aggregator import NewsAggregator
            
            aggregator = NewsAggregator(max_posts_per_digest=5)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
            title = f"üì∞ –ù–û–í–û–°–¢–ò {region.name.upper()}"
            hashtags = [f"#–ù–æ–≤–æ—Å—Ç–∏{region.code.upper()}"]
            
            digest = await aggregator.aggregate(
                posts=posts,
                title=title,
                hashtags=hashtags
            )
            
            if not digest:
                logger.error("‚ùå Failed to create digest")
                return False
            
            logger.info("‚úÖ Digest created")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±—É–¥–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ
            logger.info("\n" + "=" * 80)
            logger.info("READY TO PUBLISH:")
            logger.info("=" * 80)
            logger.info(f"Region: {region.name}")
            logger.info(f"Posts: {digest.sources_count}")
            logger.info(f"Views: {digest.total_views}")
            logger.info(f"Text: {len(digest.aggregated_text)} chars")
            logger.info("=" * 80)
            preview = digest.aggregated_text[:300]
            logger.info(preview + "...")
            logger.info("=" * 80 + "\n")
            
            logger.info("‚ö†Ô∏è  To publish to VK, use:")
            logger.info("    result = await publisher.publish_aggregated_post(digest, -YOUR_GROUP_ID)")
            logger.info("‚úÖ Full workflow is ready!")
            
            return True
            
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}", exc_info=True)
        return False


async def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    logger.info("üöÄ Starting VK Publisher tests...\n")
    
    tests = [
        ("Simple Publish", test_simple_publish),
        ("Digest Creation", test_digest_creation),
        ("Full Workflow", test_full_workflow)
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            result = await test_func()
            results.append((name, result))
            
            if result:
                logger.info(f"‚úÖ {name}: PASSED\n")
            else:
                logger.error(f"‚ùå {name}: FAILED\n")
                
        except Exception as e:
            logger.error(f"‚ùå {name}: ERROR - {e}\n", exc_info=True)
            results.append((name, False))
    
    # –ò—Ç–æ–≥–∏
    logger.info("\n" + "=" * 80)
    logger.info("TEST RESULTS")
    logger.info("=" * 80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        logger.info(f"{status}: {name}")
    
    logger.info("=" * 80)
    logger.info(f"Total: {passed}/{total} tests passed")
    logger.info("=" * 80)
    
    if passed == total:
        logger.info("\nüéâ All tests passed! VK Publisher is ready!")
        logger.info("\nüìù Next steps:")
        logger.info("   1. Add your VK group ID to config")
        logger.info("   2. Run: await publisher.publish_aggregated_post(digest, -YOUR_GROUP_ID)")
        logger.info("   3. Start Celery for automation: systemctl start setka-celery-worker")
    else:
        logger.error(f"\n‚ö†Ô∏è  {total - passed} test(s) failed")
    
    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)

